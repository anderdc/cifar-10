{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Neural Network (with Pytorch)\n",
    "\n",
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_openml\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# some vars\n",
    "batch_size = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Define transformations for dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='../data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 50000\n",
      "Testing dataset size: 10000\n",
      "Image shape: torch.Size([3, 32, 32])\n",
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "# Explore the data\n",
    "print(\"Training dataset size:\", len(train_dataset))\n",
    "print(\"Testing dataset size:\", len(test_dataset))\n",
    "\n",
    "example_image, example_label = train_dataset[0]\n",
    "print(\"Image shape:\", example_image.shape)\n",
    "\n",
    "# Get the number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "print(\"Number of classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining nn architecture\n",
    "class Cifar10NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cifar10NN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)  #the layer produces 32 output feature maps (each is a result of convolving the input with a different kernel/filter).\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 256)  # Adjusted for the output size after pooling\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "        # Pooling and dropout\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))            # after this max pooling, the tensor shape becomes (batch_size, 32, 16, 16)\n",
    "        x = self.pool(F.relu(self.conv2(x)))            # now (batch_size, 64, 8, 8)\n",
    "        x = self.pool(F.relu(self.conv3(x)))            # now (batch_size, 128, 4, 4)\n",
    "\n",
    "        # Flatten the output for the fully connected layers, 1-D\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "\n",
    "        # Fully connected layers with ReLU and dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cifar10NN(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate model, move it to gpu (if available)\n",
    "model = Cifar10NN()\n",
    "cost = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 2.237\n",
      "Epoch 1, Batch 200, Loss: 1.900\n",
      "Epoch 1, Batch 300, Loss: 1.765\n",
      "Epoch 1, Batch 400, Loss: 1.652\n",
      "Epoch 1, Batch 500, Loss: 1.580\n",
      "Epoch 1, Batch 600, Loss: 1.514\n",
      "Epoch 1, Batch 700, Loss: 1.461\n",
      "Epoch 2, Batch 100, Loss: 1.356\n",
      "Epoch 2, Batch 200, Loss: 1.352\n",
      "Epoch 2, Batch 300, Loss: 1.290\n",
      "Epoch 2, Batch 400, Loss: 1.296\n",
      "Epoch 2, Batch 500, Loss: 1.264\n",
      "Epoch 2, Batch 600, Loss: 1.230\n",
      "Epoch 2, Batch 700, Loss: 1.223\n",
      "Epoch 3, Batch 100, Loss: 1.123\n",
      "Epoch 3, Batch 200, Loss: 1.106\n",
      "Epoch 3, Batch 300, Loss: 1.137\n",
      "Epoch 3, Batch 400, Loss: 1.113\n",
      "Epoch 3, Batch 500, Loss: 1.056\n",
      "Epoch 3, Batch 600, Loss: 1.070\n",
      "Epoch 3, Batch 700, Loss: 1.076\n",
      "Epoch 4, Batch 100, Loss: 0.988\n",
      "Epoch 4, Batch 200, Loss: 0.985\n",
      "Epoch 4, Batch 300, Loss: 0.973\n",
      "Epoch 4, Batch 400, Loss: 0.971\n",
      "Epoch 4, Batch 500, Loss: 0.978\n",
      "Epoch 4, Batch 600, Loss: 0.957\n",
      "Epoch 4, Batch 700, Loss: 0.967\n",
      "Epoch 5, Batch 100, Loss: 0.880\n",
      "Epoch 5, Batch 200, Loss: 0.900\n",
      "Epoch 5, Batch 300, Loss: 0.867\n",
      "Epoch 5, Batch 400, Loss: 0.876\n",
      "Epoch 5, Batch 500, Loss: 0.884\n",
      "Epoch 5, Batch 600, Loss: 0.851\n",
      "Epoch 5, Batch 700, Loss: 0.874\n",
      "Epoch 6, Batch 100, Loss: 0.811\n",
      "Epoch 6, Batch 200, Loss: 0.800\n",
      "Epoch 6, Batch 300, Loss: 0.822\n",
      "Epoch 6, Batch 400, Loss: 0.802\n",
      "Epoch 6, Batch 500, Loss: 0.780\n",
      "Epoch 6, Batch 600, Loss: 0.802\n",
      "Epoch 6, Batch 700, Loss: 0.816\n",
      "Epoch 7, Batch 100, Loss: 0.749\n",
      "Epoch 7, Batch 200, Loss: 0.723\n",
      "Epoch 7, Batch 300, Loss: 0.718\n",
      "Epoch 7, Batch 400, Loss: 0.740\n",
      "Epoch 7, Batch 500, Loss: 0.739\n",
      "Epoch 7, Batch 600, Loss: 0.707\n",
      "Epoch 7, Batch 700, Loss: 0.756\n",
      "Epoch 8, Batch 100, Loss: 0.671\n",
      "Epoch 8, Batch 200, Loss: 0.686\n",
      "Epoch 8, Batch 300, Loss: 0.692\n",
      "Epoch 8, Batch 400, Loss: 0.685\n",
      "Epoch 8, Batch 500, Loss: 0.720\n",
      "Epoch 8, Batch 600, Loss: 0.668\n",
      "Epoch 8, Batch 700, Loss: 0.684\n",
      "Epoch 9, Batch 100, Loss: 0.590\n",
      "Epoch 9, Batch 200, Loss: 0.637\n",
      "Epoch 9, Batch 300, Loss: 0.675\n",
      "Epoch 9, Batch 400, Loss: 0.637\n",
      "Epoch 9, Batch 500, Loss: 0.638\n",
      "Epoch 9, Batch 600, Loss: 0.654\n",
      "Epoch 9, Batch 700, Loss: 0.653\n",
      "Epoch 10, Batch 100, Loss: 0.577\n",
      "Epoch 10, Batch 200, Loss: 0.588\n",
      "Epoch 10, Batch 300, Loss: 0.586\n",
      "Epoch 10, Batch 400, Loss: 0.594\n",
      "Epoch 10, Batch 500, Loss: 0.603\n",
      "Epoch 10, Batch 600, Loss: 0.610\n",
      "Epoch 10, Batch 700, Loss: 0.627\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0  # Track the loss for each epoch\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # 1. get a batch of data\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # 2. reset gradients (aside from first iteration, these have some value)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 3. run the data through the model. forward pass\n",
    "        y_pred = model(inputs)\n",
    "\n",
    "        # 4. Compute the loss\n",
    "        loss = cost(y_pred, labels)\n",
    "\n",
    "        # 5. Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # 6. update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # Print every 100 mini-batches\n",
    "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Training finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# loss plot\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sns\u001b[38;5;241m.\u001b[39mlineplot(\u001b[43mcm\u001b[49m, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cm' is not defined"
     ]
    }
   ],
   "source": [
    "# loss plot\n",
    "sns.lineplot(cm, x='epoch', y='loss', annot=True)\n",
    "plt.title(\"CNN Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 81.62%\n",
      "Test Accuracy: 71.76%\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "def evaluate(data_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.inference_mode():  # Ensures inference mode is active\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)  # Get model predictions\n",
    "            _, predicted = torch.max(outputs, 1)  # Get predicted class\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "    \n",
    "print(f\"Train Accuracy: {evaluate(train_loader):.2f}%\")    \n",
    "print(f\"Test Accuracy: {evaluate(test_loader):.2f}%\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
